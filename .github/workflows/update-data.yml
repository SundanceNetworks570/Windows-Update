name: Build MSRC updates JSON (daily)

on:
  workflow_dispatch:
  schedule:
    - cron: "9 9 * * *"  # 09:09 UTC daily

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil

      - name: Build data.json (SUG v2 global API; robust JSON handling)
        run: |
          python - << 'PY'
          import json, time, requests
          from datetime import datetime, timedelta, timezone
          from dateutil import parser as dtp

          OUT = "data.json"
          NOW = datetime.now(timezone.utc)
          SINCE = NOW - timedelta(days=30)

          def iso_to_utc(s):
              if not s:
                  return None
              try:
                  return dtp.isoparse(s).astimezone(timezone.utc)
              except Exception:
                  return None

          def best_date(u):
              for k in ("releaseDate", "currentReleaseDate", "lastModifiedDate"):
                  dt = iso_to_utc(u.get(k))
                  if dt:
                      return dt
              return None

          def safe_json(resp):
              try:
                  return resp.json()
              except Exception:
                  print(f"⚠️ Non-JSON or empty response from {resp.url} (HTTP {resp.status_code})")
                  return {"value": []}

          def fetch_json(url, tries=4, timeout=45):
              headers = {"Accept": "application/json", "User-Agent": "windows-update-board/2.1"}
              for i in range(tries):
                  try:
                      r = requests.get(url, headers=headers, timeout=timeout)
                      if r.status_code in (429, 500, 502, 503, 504):
                          print(f"Retrying after HTTP {r.status_code} ({i+1}/{tries})")
                          time.sleep(3 + i * 3)
                          continue
                      r.raise_for_status()
                      return safe_json(r)
                  except Exception as e:
                      print(f"Attempt {i+1}/{tries} failed: {e}")
                      time.sleep(2 + i * 2)
              print("❌ All attempts failed.")
              return {"value": []}

          base = "https://api.msrc.microsoft.com/sug/v2.0/updates"
          url = f"{base}?$select=title,cveIds,releaseDate,currentReleaseDate,lastModifiedDate&$orderby=lastModifiedDate desc&$top=500"

          all_rows, next_link = [], url
          while next_link:
              data = fetch_json(next_link)
              chunk = data.get("value", [])
              all_rows.extend(chunk)
              next_link = data.get("@odata.nextLink")
              if next_link:
                  print(f"→ Next page: {next_link}")

          print(f"SUG raw items seen: {len(all_rows)}")

          entries, seen = [], set()
          for u in all_rows:
              title = (u.get("title") or "").strip() or "(no description)"
              dt = best_date(u)
              if not dt or not (SINCE <= dt <= NOW):
                  continue
              for cve in (u.get("cveIds") or []):
                  if not cve:
                      continue
                  key = (cve, dt.date().isoformat())
                  if key in seen:
                      continue
                  seen.add(key)
                  entries.append({
                      "cve": cve,
                      "url": f"https://msrc.microsoft.com/update-guide/vulnerability/{cve}",
                      "releaseDate": dt.date().isoformat(),
                      "source": "MSRC-SUG",
                      "description": title
                  })

          print(f"✅ Entries kept (last 30 days): {len(entries)}")

          try:
              old = json.load(open(OUT, "r", encoding="utf-8"))
          except Exception:
              old = None

          entries.sort(key=lambda e: (e["releaseDate"], e["cve"]), reverse=True)

          if entries or old is None:
              with open(OUT, "w", encoding="utf-8") as f:
                  json.dump(entries, f, ensure_ascii=False, indent=2)
              print(f"Wrote {len(entries)} rows to {OUT}.")
          else:
              print("⚠️ No valid entries collected; preserving existing data.json.")
          PY

      - name: Commit if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): MSRC SUG v2 (resilient JSON parsing)"
          file_pattern: data.json
