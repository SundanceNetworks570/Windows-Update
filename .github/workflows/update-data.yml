name: Build MSRC updates JSON (daily)

on:
  workflow_dispatch:
  schedule:
    - cron: "9 9 * * *"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil

      - name: Build data.json (SUG v2 global API; robust date, pagination, retries)
        run: |
          python - << 'PY'
          import json, time, requests, re
          from datetime import datetime, timedelta, timezone
          from dateutil import parser as dtp

          OUT = "data.json"
          NOW = datetime.now(timezone.utc)
          SINCE = NOW - timedelta(days=30)

          def iso_dt(s):
              if not s: return None
              try:
                  return dtp.isoparse(s).astimezone(timezone.utc)
              except Exception:
                  try:
                      return datetime.strptime(s.split("T")[0], "%Y-%m-%d").replace(tzinfo=timezone.utc)
                  except Exception:
                      return None

          def pick(d, *names, default=None):
              for n in names:
                  if n in d and d[n] not in (None, "", []):
                      return d[n]
              return default

          def get_sug_page(url, headers, retries=3):
              for i in range(retries):
                  try:
                      r = requests.get(url, headers=headers, timeout=45)
                      if r.status_code == 429:
                          time.sleep(2 + i*2)
                          continue
                      r.raise_for_status()
                      return r.json()
                  except Exception as e:
                      if i == retries - 1:
                          raise
                      time.sleep(2 + i*2)
              return {"value": []}

          BASE = "https://api.msrc.microsoft.com/sug/v2.0/updates"
          headers = {"Accept": "application/json"}

          url = BASE
          entries, seen = [], set()
          total_seen_raw = 0

          print(f"Fetching data from: {BASE}")
          while url:
              data = get_sug_page(url, headers)
              items = data.get("value", [])
              total_seen_raw += len(items)

              for u in items:
                  title = pick(u, "title", "Title", default="").strip()
                  cves = pick(u, "cveNumbers", "CVEIDs", "cveNumber", default=[]) or []
                  if isinstance(cves, str):
                      cves = [cves]

                  # --- handle multiple possible date fields ---
                  pub = iso_dt(pick(u, "releaseDate", "ReleaseDate", "initialReleaseDate", "lastModifiedDate", "publishDate"))
                  if not pub:
                      continue
                  
                  # Some MSRC data lists future dates (scheduled patches)
                  if pub > NOW:
                      continue

                  if not (SINCE <= pub <= NOW + timedelta(days=1)):
                      continue

                  for cve in cves:
                      cve = cve.strip()
                      if not cve:
                          continue
                      key = (cve, pub.date().isoformat())
                      if key in seen:
                          continue
                      seen.add(key)
                      entries.append({
                          "cve": cve,
                          "url": f"https://msrc.microsoft.com/update-guide/vulnerability/{cve}",
                          "releaseDate": pub.date().isoformat(),
                          "source": "MSRC-SUG",
                          "description": title or "(no description)"
                      })

              url = data.get("@odata.nextLink")

          print(f"SUG raw items seen: {total_seen_raw}; entries kept (last 30 days): {len(entries)}")

          if not entries:
              print("WARNING: No entries were collected. Keeping previous data.json if present.")
              try:
                  with open(OUT, "r", encoding="utf-8") as f:
                      old = json.load(f)
                  print(f"Preserved existing data.json with {len(old)} entries.")
              except Exception:
                  with open(OUT, "w", encoding="utf-8") as f:
                      json.dump([], f, ensure_ascii=False, indent=2)
                  print("Created empty data.json (no prior file).")
              raise SystemExit(0)

          entries.sort(key=lambda e: (e["releaseDate"], e["cve"]), reverse=True)
          print(f"Writing {len(entries)} entries covering {SINCE.date()}..{NOW.date()}")
          with open(OUT, "w", encoding="utf-8") as f:
              json.dump(entries, f, ensure_ascii=False, indent=2)
          PY

      - name: Commit if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): MSRC updates via SUG v2 API (fixed date logic)"
          file_pattern: data.json
