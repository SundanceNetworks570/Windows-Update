name: Build MSRC updates JSON (daily)

on:
  schedule:
    - cron: "9 9 * * *"  # Daily at 09:09 UTC
  workflow_dispatch:
    inputs:
      days_back:
        description: "Number of days back to collect"
        required: false
        default: "30"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests xmltodict python-dateutil pytz

      - name: Build data.json (real CVRF parsing)
        env:
          DAYS_BACK_INPUT: ${{ github.event.inputs.days_back }}
        run: |
          python - <<'PY'
          import os, json, requests, xmltodict
          from datetime import datetime, timedelta, timezone
          from dateutil.parser import isoparse

          # --- Setup ---
          days_back = int(os.getenv("DAYS_BACK_INPUT") or "30")
          NOW = datetime.now(timezone.utc)
          SINCE = NOW - timedelta(days=days_back)

          def log(msg): print(msg, flush=True)

          def clean_text(s):
              if not s:
                  return ""
              if isinstance(s, dict):
                  s = s.get("#text") or ""
              return str(s).replace("\n", " ").replace("\r", " ").strip()

          def get_months():
              months = [NOW.strftime("%Y-%b")]
              prev = (NOW.replace(day=1) - timedelta(days=1)).strftime("%Y-%b")
              if prev not in months:
                  months.append(prev)
              return months

          def fetch_cvrf(month):
              url = f"https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/{month}"
              log(f"Fetching {url}")
              try:
                  r = requests.get(url, headers={"Accept": "application/xml"}, timeout=30)
                  if r.status_code == 404:
                      log(f"No CVRF data for {month}")
                      return None
                  r.raise_for_status()
                  return xmltodict.parse(r.text)
              except Exception as e:
                  log(f"Error fetching {month}: {e}")
                  return None

          def extract_vulns(doc):
              vulns = []
              if not doc:
                  return vulns
              root = doc.get("cvrfdoc", {})
              tracking = root.get("DocumentTracking", {})
              cur_date = tracking.get("CurrentReleaseDate") or tracking.get("InitialReleaseDate")

              if isinstance(cur_date, dict):
                  cur_date = cur_date.get("#text")
              try:
                  dt = isoparse(cur_date)
              except Exception:
                  dt = NOW

              if dt < SINCE:
                  return []

              for v in root.get("Vulnerability", []):
                  title = clean_text(v.get("Title"))
                  cve = v.get("CVE") or "Unknown CVE"
                  if isinstance(cve, list):
                      cve = ", ".join(cve)
                  desc = ""
                  notes = v.get("Notes", {}).get("Note") if isinstance(v.get("Notes"), dict) else []
                  if isinstance(notes, list):
                      for n in notes:
                          if isinstance(n, dict) and n.get("@Type") == "Description":
                              desc = clean_text(n.get("#text"))
                              break
                  elif isinstance(notes, dict):
                      desc = clean_text(notes.get("#text"))

                  vulns.append({
                      "title": title or "(no title)",
                      "cve": cve,
                      "description": desc or "(no description)",
                      "releaseDate": dt.isoformat(),
                      "source": "CVRF"
                  })
              return vulns

          all_items = []
          for m in get_months():
              data = fetch_cvrf(m)
              vulns = extract_vulns(data)
              log(f"Extracted {len(vulns)} vulnerabilities from {m}")
              all_items.extend(vulns)

          # Filter to last N days
          recent = []
          for v in all_items:
              try:
                  d = isoparse(v["releaseDate"])
                  if SINCE <= d <= NOW:
                      recent.append(v)
              except Exception:
                  continue

          log(f"Total entries within {days_back} days: {len(recent)}")

          if not recent:
              if os.path.exists("data.json"):
                  log("No new data — preserving existing file.")
              else:
                  recent = [{"title": "No updates", "cve": "-", "description": "-", "releaseDate": NOW.isoformat(), "source": "none"}]

          with open("data.json", "w", encoding="utf-8") as f:
              json.dump(recent, f, indent=2, ensure_ascii=False)
              log("✅ data.json written successfully.")
          PY

      - name: Commit if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update MSRC data.json"
          file_pattern: data.json
