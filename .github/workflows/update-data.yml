name: Build MSRC updates JSON (fast)

on:
  workflow_dispatch:
  # Uncomment if you also want a schedule for the fast job
  # schedule:
  #   - cron: "45 9 * * *"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests feedparser python-dateutil

      - name: Build data.json (SUG v2: API with quick RSS fallback)
        run: |
          python - <<'PY'
          import json, time, random, requests, feedparser
          from datetime import datetime, timedelta, timezone
          from dateutil.parser import isoparse

          NOW = datetime.now(timezone.utc)
          SINCE = NOW - timedelta(days=30)

          def log(m): print(m, flush=True)

          def fetch_sug_json_quick():
              url = ("https://api.msrc.microsoft.com/sug/v2.0/updates"
                     "?$select=title,cveIds,releaseDate,lastModifiedDate,severity,releaseNumber"
                     "&$orderby=lastModifiedDate desc&$top=200")
              headers = {"User-Agent": "Mozilla/5.0 (compatible; MSRCFast/1.0)"}
              for attempt in range(2):  # quick: 2 tries only
                  try:
                      r = requests.get(url, headers=headers, timeout=25)
                      if r.status_code == 200:
                          return r.json().get("value", [])
                      if r.status_code in (999, 429, 503):
                          backoff = 6 + random.randint(2, 6)
                          log(f"SUG HTTP {r.status_code}, retrying in {backoff}s [{attempt+1}/2]...")
                          time.sleep(backoff)
                      else:
                          log(f"SUG HTTP {r.status_code} (no retry)")
                          return []
                  except Exception as e:
                      log(f"SUG error: {e} (retrying quick)")
                      time.sleep(6)
              return []

          def fetch_sug_rss():
              log("Falling back to SUG RSS…")
              rss_url = "https://api.msrc.microsoft.com/update-guide/rss"
              feed = feedparser.parse(rss_url)
              items = []
              for e in feed.entries:
                  # published_parsed can be None for some items; skip those
                  if not getattr(e, "published_parsed", None):
                      continue
                  pub = datetime(*e.published_parsed[:6], tzinfo=timezone.utc)
                  if pub < SINCE: 
                      continue
                  items.append({
                      "title": e.title,
                      "cve": getattr(e, "id", "N/A"),
                      "description": getattr(e, "summary", "(no description)"),
                      "severity": "N/A",
                      "releaseDate": pub.strftime("%Y-%m-%d"),
                      "source": "SUG RSS"
                  })
              log(f"RSS parsed: {len(items)}")
              return items

          all_entries = []
          log("Fetching SUG JSON (fast)…")
          data = fetch_sug_json_quick()
          if not data:
              data = fetch_sug_rss()

          for item in data:
              rd = item.get("releaseDate")
              try:
                  dt = isoparse(rd) if rd else None
              except Exception:
                  dt = None
              if dt and dt >= SINCE:
                  all_entries.append({
                      "title": item.get("title", "(no title)"),
                      "cve": ", ".join(item.get("cveIds", [])) if isinstance(item.get("cveIds"), list) else str(item.get("cveIds") or "N/A"),
                      "description": item.get("releaseNumber", "Windows Update"),
                      "severity": item.get("severity", "N/A"),
                      "releaseDate": dt.strftime("%Y-%m-%d"),
                      "source": item.get("source", "SUG")
                  })

          all_entries.sort(key=lambda x: x["releaseDate"], reverse=True)

          with open("data.json", "w", encoding="utf-8") as f:
              json.dump(all_entries, f, indent=2, ensure_ascii=False)

          log(f"✅ Fast build saved {len(all_entries)} entries to data.json")
          PY

      - name: Commit if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "update data.json (FAST SUG)"
          file_pattern: data.json
