name: Build MSRC updates JSON (fast)

on:
  workflow_dispatch:
    inputs:
      days_back:
        description: "How many days back to fetch (recommended: 7)"
        required: false
        default: "7"
  schedule:
    # Daily at 09:05 UTC (staggered a bit)
    - cron: "5 9 * * *"

concurrency:
  group: msrc-json-fast
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    # Hard stop so it can't run forever
    timeout-minutes: 12

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Build data.json (SUG v2; fast retries & 7-day default)
        env:
          DAYS_BACK: ${{ inputs.days_back }}
        shell: bash
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, json, time, random
          from datetime import datetime, timedelta, timezone
          import requests

          # --- config (fast profile)
          days_back = int(os.getenv("DAYS_BACK") or "7")   # default 7; pass 30 when needed
          max_attempts = 6                                 # 6 tries max
          backoffs = [10, 20, 40, 60, 90, 120]            # ~5.5 min worst-case wait
          timeout_sec = 25                                 # per request timeout
          top_n = 200                                      # server-side cap

          now = datetime.now(timezone.utc)
          start = now - timedelta(days=days_back)

          # MSRC SUG v2: filter strictly by releaseDate window
          # NOTE: MSRC expects RFC3339 timestamps with 'Z'
          def iso(dt): return dt.replace(microsecond=0).isoformat().replace("+00:00","Z")
          url = (
            "https://api.msrc.microsoft.com/sug/v2.0/updates"
            f"?$select=title,cveIds,releaseDate,lastModifiedDate,productFamily"
            f"&$filter=releaseDate ge {iso(start)} and releaseDate le {iso(now)}"
            f"&$orderby=releaseDate desc"
            f"&$top={top_n}"
          )

          headers = {"Accept": "application/json"}

          def fetch_with_retries(u):
            for i in range(max_attempts):
              try:
                r = requests.get(u, headers=headers, timeout=timeout_sec)
                # HTTP 429 or 999 are throttle-ish; treat as retryable
                if r.status_code in (429, 499, 500, 502, 503, 504, 999):
                  delay = backoffs[i] if i < len(backoffs) else backoffs[-1]
                  print(f"‚ö†Ô∏è  MSRC rate/temporary error (HTTP {r.status_code}); retrying in {delay}s‚Ä¶ ({i+1}/{max_attempts})")
                  time.sleep(delay + random.uniform(0, 1.5))
                  continue
                r.raise_for_status()
                try:
                  return r.json()
                except Exception:
                  delay = backoffs[i] if i < len(backoffs) else backoffs[-1]
                  print(f"‚ö†Ô∏è  Non-JSON response; retrying in {delay}s‚Ä¶ ({i+1}/{max_attempts})")
                  time.sleep(delay + random.uniform(0, 1.5))
                  continue
              except requests.RequestException as e:
                delay = backoffs[i] if i < len(backoffs) else backoffs[-1]
                print(f"‚ö†Ô∏è  Network/API error: {e}; retrying in {delay}s‚Ä¶ ({i+1}/{max_attempts})")
                time.sleep(delay + random.uniform(0, 1.5))
            print("‚ùå All retries exhausted or invalid JSON. Returning empty set.")
            return {"value": []}

          raw = fetch_with_retries(url)
          items = raw.get("value", [])

          # Extra safety: keep only items within window and normalize fields
          kept = []
          def parse_dt(s):
            try:
              # Handles "YYYY-MM-DDTHH:MM:SSZ" and with offset
              if s.endswith("Z"):  # quick path
                return datetime.fromisoformat(s.replace("Z","+00:00"))
              return datetime.fromisoformat(s)
            except Exception:
              return None

          for it in items:
            rd = parse_dt(str(it.get("releaseDate","")))
            if not rd: 
              continue
            if rd < start or rd > now:
              continue
            kept.append({
              "title": it.get("title"),
              "cveIds": it.get("cveIds", []),
              "releaseDate": rd.isoformat(),
              "lastModifiedDate": str(it.get("lastModifiedDate")),
              "productFamily": it.get("productFamily")
            })

          kept.sort(key=lambda x: x["releaseDate"], reverse=True)
          print(f"‚úÖ Entries kept (last {days_back} days): {len(kept)}")

          if kept:
            with open("data.json","w",encoding="utf-8") as f:
              json.dump(kept, f, ensure_ascii=False, indent=2)
            print(f"üíæ Wrote {len(kept)} rows to data.json")
          else:
            # Preserve existing file so the website doesn‚Äôt blank out
            if os.path.exists("data.json"):
              print("‚ÑπÔ∏è  No valid entries found ‚Äî preserving existing data.json.")
            else:
              with open("data.json","w",encoding="utf-8") as f:
                json.dump([], f)
              print("‚ÑπÔ∏è  No entries and no prior file; created empty data.json.")
          PY

      - name: Commit if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): MSRC data.json (last ${{ inputs.days_back || '7' }} days)"
          file_pattern: data.json
